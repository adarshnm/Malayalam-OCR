{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1471b3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:35:03.478746Z",
     "start_time": "2021-11-26T05:35:03.461735Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.keras import layers as kl\n",
    "\n",
    "from capsnet import nn, layers, losses\n",
    "from capsnet.layers import ConvCaps2D, DenseCaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f42c3a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:35:10.214331Z",
     "start_time": "2021-11-26T05:35:10.200312Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "img_height = 32\n",
    "img_width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17cb37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:26:32.289937Z",
     "start_time": "2021-11-26T05:26:30.463526Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'D:/Projects/Research/MalayalamOCR/Handwritten-Dataset/dataset_u4/'\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=124,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "color_mode = 'grayscale',\n",
    "label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c432280",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:26:34.002314Z",
     "start_time": "2021-11-26T05:26:32.293942Z"
    }
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=124,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "color_mode = 'grayscale',\n",
    "label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d9462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:31:47.121400Z",
     "start_time": "2021-11-26T05:31:47.103412Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1677d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:32:02.604943Z",
     "start_time": "2021-11-26T05:32:02.571938Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9a082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:26:34.017326Z",
     "start_time": "2021-11-26T05:26:34.004314Z"
    }
   },
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "test_dataset = val_ds.take(val_batches // 5)\n",
    "val_ds = val_ds.skip(val_batches // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504e7ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:26:34.032330Z",
     "start_time": "2021-11-26T05:26:34.020320Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f10bb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:26:34.048342Z",
     "start_time": "2021-11-26T05:26:34.034326Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "# train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2e830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:16:53.312820Z",
     "start_time": "2021-11-26T05:16:53.298818Z"
    }
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17dea67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:16:53.328906Z",
     "start_time": "2021-11-26T05:16:53.313821Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "IMG_SHAPE = (img_width, img_height, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1b898c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:35:20.546926Z",
     "start_time": "2021-11-26T05:35:15.657529Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\Research\\MalayalamOCR\\OfflineHandwrittenOCR\\lib\\utils.py:223: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  dataset = np.array(dataset)\n"
     ]
    }
   ],
   "source": [
    "from lib.utils import *\n",
    "(X_train, y_train), (X_test, y_test), (X_val, y_val) = load_32x32_min_train_test_val_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f5c5fc",
   "metadata": {},
   "source": [
    "## CapsNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435bb421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:35:24.102091Z",
     "start_time": "2021-11-26T05:35:24.068104Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(name, input_shape, num_classes) -> k.Model:\n",
    "    if name == \"original\":\n",
    "        return original_model(name, input_shape, num_classes)\n",
    "    elif name == \"deepcaps\":\n",
    "        return deep_caps_model(name, input_shape, num_classes)\n",
    "    else:\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def original_model(name, input_shape, num_classes) -> k.Model:\n",
    "    inl = kl.Input(shape=input_shape, name='input')\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1./255) (inl)\n",
    "    \n",
    "    # relu convolution for feature extraction\n",
    "    nl = kl.Conv2D(filters=256, kernel_size=(9, 9), strides=(\n",
    "        1, 1), activation='relu', name='conv')(normalization_layer)\n",
    "    # convert to capsule domain\n",
    "    nl = ConvCaps2D(filters=32, filter_dims=8, kernel_size=(\n",
    "        9, 9), strides=(2, 2), name='conv_caps_2d')(nl)\n",
    "    nl = kl.Lambda(nn.squash)(nl)\n",
    "    # dense layer for dynamic routing\n",
    "    nl = DenseCaps(caps=num_classes, caps_dims=16,\n",
    "                   routing_iter=3, name='dense_caps')(nl)\n",
    "    nl = kl.Lambda(nn.squash)(nl)\n",
    "    pred = kl.Lambda(nn.norm, name='pred')(nl)\n",
    "    recon = fully_connected_decoder(input_shape)(nl)\n",
    "    return k.Model(inputs=inl, outputs=[pred, recon], name=name)\n",
    "\n",
    "\n",
    "def fully_connected_decoder(target_shape):\n",
    "    def decoder(input_tensor):\n",
    "        nl = nn.MaskCID(name=\"dc_masking\")(input_tensor)\n",
    "        nl = kl.Dense(512, activation='relu', name=\"dc_dense_1\")(nl)\n",
    "        nl = kl.Dense(1024, activation='relu', name=\"dc_dense_2\")(nl)\n",
    "        nl = kl.Dense(tf.reduce_prod(target_shape),\n",
    "                      activation='sigmoid', name=\"dc_dense_3\")(nl)\n",
    "        nl = kl.Reshape(target_shape, name='recon')(nl)\n",
    "        return nl\n",
    "\n",
    "    return decoder\n",
    "\n",
    "\n",
    "def deep_caps_model(name, input_shape, num_classes) -> k.Model:\n",
    "    inl = k.layers.Input(shape=input_shape, name='input')\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1./255) (inl)\n",
    "    kernel_size = (3, 3)\n",
    "    # relu convolution for feature extraction\n",
    "    nl = kl.Conv2D(filters=128, kernel_size=kernel_size, strides=(\n",
    "        1, 1), activation='relu', padding='same', name='conv')(normalization_layer)\n",
    "    # residual capsule block 1\n",
    "    l2 = dense_caps_block(filters=16, filter_dims=8,\n",
    "                          kernel_size=kernel_size, strides=(2, 2), routing_iter=3)(nl)\n",
    "    # residual capsule block 2\n",
    "    l3 = dense_caps_block(filters=16, filter_dims=16,\n",
    "                          kernel_size=kernel_size, strides=(2, 2), routing_iter=3)(l2)\n",
    "    # flatten capsules\n",
    "    nl = layers.FlattenCaps(caps=num_classes, name='cap1_flatten')(l3)\n",
    "    pred = k.layers.Lambda(nn.norm, name='pred')(nl)\n",
    "    recon = conv_decoder(target_shape=input_shape)(nl)\n",
    "    return k.models.Model(inputs=inl, outputs=[pred, recon], name=name)\n",
    "\n",
    "\n",
    "def dense_caps_block(filters, filter_dims, kernel_size, strides, routing_iter):\n",
    "    def block(il):\n",
    "        l0 = layers.ConvCaps2D(filters, filter_dims,\n",
    "                               kernel_size, strides, padding='same')(il)\n",
    "        l1 = layers.ConvCaps3D(\n",
    "            filters, filter_dims, routing_iter, kernel_size, (1, 1), padding='same')(l0)\n",
    "        l2 = kl.Concatenate(axis=-1)([l0, l1])\n",
    "        return kl.Lambda(nn.squash)(l2)\n",
    "\n",
    "    return block\n",
    "\n",
    "\n",
    "def conv_decoder(target_shape):\n",
    "    conv_params = {'kernel_size': (3, 3), 'strides': (\n",
    "        2, 2), 'activation': 'relu', 'padding': 'same'}\n",
    "    W, D, N = target_shape[0], target_shape[2], 0\n",
    "    while W // (2 ** N) > 4 and W % (2 ** N) == 0:\n",
    "        N = N + 1\n",
    "    N = N - 1\n",
    "    W_S = W // (2 ** N)\n",
    "\n",
    "    def decoder(input_tensor):\n",
    "        nl = nn.MaskCID(name=\"dc_masking\")(input_tensor)\n",
    "        nl = kl.Dense(W_S * W_S * D, name=\"dc_dense\")(nl)\n",
    "        nl = kl.BatchNormalization(momentum=0.8, name=\"dc_batch_norm\")(nl)\n",
    "        nl = kl.Reshape((W_S, W_S, D), name=\"dc_reshape\")(nl)\n",
    "        for i in range(N - 1):\n",
    "            nl = kl.Conv2DTranspose(\n",
    "                filters=64 * (N - i), **conv_params, name=f\"decoder_dconv_{i + 1}\")(nl)\n",
    "        nl = kl.Conv2DTranspose(filters=D, **conv_params, name=\"recon\")(nl)\n",
    "        return nl\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051d2468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:35:25.840314Z",
     "start_time": "2021-11-26T05:35:25.833321Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.0005\n",
    "b1 = 0.9\n",
    "b2 = 0.999 \n",
    "ep = 1e-07\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c152416e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:06:16.364257Z",
     "start_time": "2021-11-26T06:06:16.184215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepcaps\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_1 (Rescaling)         (None, 32, 32, 1)    0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv (Conv2D)                   (None, 32, 32, 128)  1280        rescaling_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_caps2d_2 (ConvCaps2D)      (None, 16, 16, 16, 8 9344        conv[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv_caps3d_2 (ConvCaps3D)      (None, 16, 16, 16, 8 9344        conv_caps2d_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 16, 1 0           conv_caps2d_2[0][0]              \n",
      "                                                                 conv_caps3d_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16, 16, 16, 1 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_caps2d_3 (ConvCaps2D)      (None, 8, 8, 16, 16) 590080      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_caps3d_3 (ConvCaps3D)      (None, 8, 8, 16, 16) 37120       conv_caps2d_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 16, 32) 0           conv_caps2d_3[0][0]              \n",
      "                                                                 conv_caps3d_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 8, 8, 16, 32) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cap1_flatten (FlattenCaps)      (None, 121, 32)      123904      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dc_masking (MaskCID)            (None, 32)           0           cap1_flatten[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dc_dense (Dense)                (None, 64)           2112        dc_masking[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dc_batch_norm (BatchNormalizati (None, 64)           256         dc_dense[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dc_reshape (Reshape)            (None, 8, 8, 1)      0           dc_batch_norm[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dconv_1 (Conv2DTranspos (None, 16, 16, 128)  1280        dc_reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pred (Lambda)                   (None, 121)          0           cap1_flatten[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "recon (Conv2DTranspose)         (None, 32, 32, 1)    1153        decoder_dconv_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 775,873\n",
      "Trainable params: 775,745\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "  model = get_model(name='deepcaps', input_shape=(32,32,1), num_classes=121)\n",
    "  model.compile(optimizer=k.optimizers.Adam(learning_rate=0.001, clipnorm=1.0, clipvalue=0.5),\n",
    "                loss=[lambda a, b: losses.margin_loss(a, b, 0.9, 0.01), 'mse'],\n",
    "                loss_weights=[1, 5e-3],\n",
    "                metrics={'pred': 'acc'})\n",
    "  model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "187f76e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:42:35.948332Z",
     "start_time": "2021-11-26T05:42:35.940316Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'models/checkpoints/vggnet/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daee646e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:08:30.944381Z",
     "start_time": "2021-11-26T06:06:23.486776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2057/2057 [==============================] - 115s 55ms/step - loss: 0.0068 - pred_loss: 0.0065 - recon_loss: 0.0462 - pred_acc: 0.0079 - val_loss: 0.0066 - val_pred_loss: 0.0064 - val_recon_loss: 0.0280 - val_pred_acc: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv3d_layer_call_and_return_conditional_losses, conv3d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/checkpoints/vggnet\\checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/checkpoints/vggnet\\checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      " 193/2057 [=>............................] - ETA: 1:32 - loss: 0.0066 - pred_loss: 0.0064 - recon_loss: 0.0281 - pred_acc: 0.0067"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3104/3183129250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(X_train, [y_train, X_train],\n\u001b[0m\u001b[0;32m      3\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint = k.callbacks.ModelCheckpoint(checkpoint_filepath, save_best_only=True)\n",
    "history = model.fit(X_train, [y_train, X_train],\n",
    "              batch_size=20,\n",
    "              epochs=100,\n",
    "              validation_data=(X_test, (y_test, X_test)),\n",
    "              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b622f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:26:42.198117Z",
     "start_time": "2021-11-26T05:26:42.115101Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "      callbacks=[model_checkpoint_callback],\n",
    "  epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8934054",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:03.520414Z",
     "start_time": "2021-11-26T03:59:03.863591Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_p, accuracy = model.evaluate(val_ds)\n",
    "accuracy = accuracy * 100\n",
    "print(f\"Loss: {loss_p:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8dac67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:03.551229Z",
     "start_time": "2021-11-26T04:01:03.524402Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.now()\n",
    "folder_name = f'{today.hour}-{today.minute}_{today.day:02d}-{today.month}-{today.year}'\n",
    "path = os.path.join('results','model_summary','vggnet',folder_name)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "model_folder = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca5fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:03.566355Z",
     "start_time": "2021-11-26T04:01:03.553219Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(history.history, open(model_folder+'\\history.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d091767",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:03.829985Z",
     "start_time": "2021-11-26T04:01:03.569356Z"
    }
   },
   "outputs": [],
   "source": [
    "# save as file\n",
    "model.save(f'models/model_{num_classes}_vggnet_224x224_{today.hour}-{today.minute}_{today.day:02d}-{today.month}-{today.year}-acc{int(accuracy)}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1addce79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:06.845847Z",
     "start_time": "2021-11-26T04:01:03.831984Z"
    }
   },
   "outputs": [],
   "source": [
    "# save as directory\n",
    "model.save(model_folder+'\\model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74d796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:06.939900Z",
     "start_time": "2021-11-26T04:01:06.846846Z"
    }
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "model.save_weights(model_folder+f'/model_{num_classes}-acc{int(accuracy)}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47220820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:07.273070Z",
     "start_time": "2021-11-26T04:01:06.941888Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(model_folder+'\\combined.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e6f66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:07.415812Z",
     "start_time": "2021-11-26T04:01:07.275073Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],label=\"Loss\")\n",
    "plt.plot(history.history['val_loss'],label=\"Val Loss\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(model_folder+'\\loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19e05e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:07.557588Z",
     "start_time": "2021-11-26T04:01:07.417813Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],label=\"Accuracy\")\n",
    "plt.plot(history.history['val_accuracy'],label=\"Val Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(model_folder+'\\\\accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd4468",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a114c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:07.573580Z",
     "start_time": "2021-11-26T04:01:07.559578Z"
    }
   },
   "outputs": [],
   "source": [
    "# backup \n",
    "og_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8c545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:07.589269Z",
     "start_time": "2021-11-26T04:01:07.575580Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of layers in the base model: \", len(basemodel.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dff884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:07.604956Z",
     "start_time": "2021-11-26T04:01:07.590276Z"
    }
   },
   "outputs": [],
   "source": [
    "basemodel.trainable = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe0253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:37.323762Z",
     "start_time": "2021-11-26T04:01:37.309758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 10\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in basemodel.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3991e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:38.211267Z",
     "start_time": "2021-11-26T04:01:38.205278Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-05\n",
    "b1 = 0.9\n",
    "b2 = 0.999 \n",
    "ep = 1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e649f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:39.191953Z",
     "start_time": "2021-11-26T04:01:39.167644Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'models/checkpoints/vggnet'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=lr, beta_1=b1,beta_2=b2, epsilon=ep, decay=0.0),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd565877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:01:40.264442Z",
     "start_time": "2021-11-26T04:01:40.259440Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ae8d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:22:11.385905Z",
     "start_time": "2021-11-26T04:02:03.042053Z"
    }
   },
   "outputs": [],
   "source": [
    "fine_tune_epochs = 4\n",
    "total_epochs =  EPOCHS + fine_tune_epochs\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                        callbacks=[model_checkpoint_callback],\n",
    "                         validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647c633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:23:59.240843Z",
     "start_time": "2021-11-26T04:23:59.198100Z"
    }
   },
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4f09f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:00.238858Z",
     "start_time": "2021-11-26T04:23:59.765188Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([EPOCHS-1,EPOCHS-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(model_folder+'\\combined_finetuned.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5744f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:10.149420Z",
     "start_time": "2021-11-26T04:24:03.813965Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_finetuned, accuracy_finetuned = model.evaluate(test_dataset)\n",
    "accuracy_finetuned = accuracy_finetuned * 100\n",
    "print('Test accuracy :', accuracy_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad70466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:15.349371Z",
     "start_time": "2021-11-26T04:24:15.311352Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_word(num):\n",
    "    pred = ''\n",
    "    ch = class_names[num]\n",
    "    lis = ch.split(' ')\n",
    "    char_list = [chr(int(i)) for i in lis]\n",
    "    pred += ''.join(char_list)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce03f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:17.641024Z",
     "start_time": "2021-11-26T04:24:16.170550Z"
    }
   },
   "outputs": [],
   "source": [
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73496e40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:18.033569Z",
     "start_time": "2021-11-26T04:24:18.024565Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1a094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:18.924394Z",
     "start_time": "2021-11-26T04:24:18.905382Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "from pathlib import Path\n",
    "# point to the font location with an absolute path\n",
    "nirm = Path('c:/Windows/Fonts/kartika.ttf')\n",
    "\n",
    "# configure the Hindi font\n",
    "mal_font = FontProperties(fname=nirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a6ffb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:21.903172Z",
     "start_time": "2021-11-26T04:24:20.193027Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  pred_word = predict_word(predictions[i])\n",
    "  plt.title(pred_word,fontproperties=mal_font)\n",
    "  plt.savefig(model_folder+'\\prediction.jpg')\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a059c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:22.170066Z",
     "start_time": "2021-11-26T04:24:21.907154Z"
    }
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "model.save_weights(model_folder+f'/model_{num_classes}_vggnet_finetuned_{today.hour}-{today.minute}_{today.day:02d}-{today.month}-{today.year}-acc{int(accuracy)}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269bf5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:26.385737Z",
     "start_time": "2021-11-26T04:24:22.173067Z"
    }
   },
   "outputs": [],
   "source": [
    "# save as directory\n",
    "model.save(model_folder+f'\\model_finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ae01a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:26.401740Z",
     "start_time": "2021-11-26T04:24:26.387738Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = np.array(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b74453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:26.417762Z",
     "start_time": "2021-11-26T04:24:26.404741Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(model_folder+'\\class_names.npy', 'wb') as f:\n",
    "    np.save(f, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12dd01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:26.433750Z",
     "start_time": "2021-11-26T04:24:26.420749Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(history_fine.history, open(model_folder+'\\history_fine.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463f329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T04:24:26.449751Z",
     "start_time": "2021-11-26T04:24:26.435751Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open(model_folder+\"\\\\config.txt\", \"w\")\n",
    "f.writelines([f'LR: {lr}\\n',f'Beta 1:{b1}\\n',f'Beta 2:{b2}\\n',f'Classes: {num_classes}',f'epsilon:{ep}\\n',f'epochs:{EPOCHS}\\n',f'accuracy: {accuracy}\\n',f'accuracy finetuned: {accuracy_finetuned}\\n'])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f48520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e57f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e33cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
